{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import nltk \n",
    "import copy\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext.vocab as vocab\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "list_of_phonemes = ['AA','AE','AH','AO','AW','AY','B','CH','D','DH','EH','ER','EY','F','G', 'HH', 'IH', 'IY','JH','K','L','M','N','NG','OW','OY','P','R','S','SH','T','TH','UH','UW','V','W','Y','Z','ZH']\n",
    "vowels=['AA','AE','AH','AO','AW','AY','EH','ER','EY','IH','IY','OW','OY','UH','UW','Y']\n",
    "arpabet = nltk.corpus.cmudict.dict()\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a pronunciation and returns a list of the vowels that appeared in it\n",
    "def get_vowels(pronunciation):\n",
    "    found_vowels = []\n",
    "    for sound in pronunciation:\n",
    "        if sound in vowels:\n",
    "            found_vowels.append(sound)\n",
    "    return found_vowels\n",
    "\n",
    "def nonzero(thing):\n",
    "    return (len(thing)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip:   1%|          | 6.70M/862M [00:06<14:43, 969kB/s]    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d4e152ca418f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'6B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded {} words'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'glove.{}.{}d.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    314\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove the partial zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting vectors into {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    311\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                             \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove the partial zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "glove = vocab.GloVe(name='6B', dim=100)\n",
    "\n",
    "print('Loaded {} words'.format(len(glove.itos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(word):\n",
    "    return glove.vectors[glove.stoi[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/maximus/fall/seq2seq_raplyrics'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.normpath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataFrame(Dataset):\n",
    "    def __init__(self, root_dir, max_len):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with lyric files. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.phonemes2index = {0: \"<SOS>\", 1: \"<EOS>\", 2: \"<PAD>\"}\n",
    "        self.phonemes2count = {}\n",
    "        self.index2phonemes = {}\n",
    "        \n",
    "        self.words2index = {}\n",
    "        self.words2count = {}\n",
    "        self.index2words = {0: \"<SOS>\", 1: \"<EOS>\", 2: \"<PAD>\"}\n",
    "        #self.words2prob = {}\n",
    "        #self.words2probReverse = {}\n",
    "        \n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "        self.n_phonemes = 3\n",
    "        \n",
    "        self.word2phoneme = {}\n",
    "        \n",
    "        self.max_len = max_len\n",
    "        # takes the two files 'words_in_lyrics' and 'pho_dict' to construct\n",
    "        # a dictionary that stores word to pronunciation conversions\n",
    "        lst = [(\"<SOS>\",\"<SOS>\"),(\"<EOS>\",\"<EOS>\"),(\"<PAD>\",\"<PAD>\")]\n",
    "        data_dir = os.path.normpath(os.getcwd() + \"/data\")\n",
    "        words = [word.rstrip('\\n') for word in open(data_dir + '/words_in_lyrics')]\n",
    "        pronunciations = [word.rstrip('\\n') for word in open(data_dir + '/pho_dict')]\n",
    "        for ind in range(len(words)):\n",
    "            lst.append((words[ind], pronunciations[ind].split()))\n",
    "            \n",
    "        self.word2pho = dict(lst)\n",
    "        \n",
    "        \n",
    "        self.pairs = []\n",
    "        # table is for removing odd characters\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        print(\"Reading lyrics...\")\n",
    "        error_counter = 0\n",
    "        for file in os.listdir(data_dir + '/' + root_dir):\n",
    "            print(file)\n",
    "            with open(data_dir + '/lyric_files/' + file) as f:\n",
    "                data = json.load(f)\n",
    "                for song in data['songs']:\n",
    "                    lines = [w.translate(table).lower() for w in song['lyrics'].split('\\n')]\n",
    "                    lines_filtered = [i for i in lines if len(i)>0]\n",
    "                    lines = lines_filtered \n",
    "                    for ind in range(len(lines)-1):\n",
    "                        line1 = lines[ind].split()\n",
    "                        line2 = lines[ind+1].split()\n",
    "\n",
    "                        #this gets rid of weird non-ascii characters like right quote and stuff like that \n",
    "                        line1 = [w.encode('ascii',errors='ignore').decode() for w in line1 if len(w.encode('ascii',errors='ignore').decode())>0]\n",
    "                        line2 = [w.encode('ascii',errors='ignore').decode() for w in line2 if len(w.encode('ascii',errors='ignore').decode())>0]\n",
    "                        #Add 'EOS' and 'BOS' tokens\n",
    "                        try:\n",
    "                            line1_vowels = get_vowels(self.word2pho[line1[-1]])\n",
    "                            line2_vowels = get_vowels(self.word2pho[line2[-1]])\n",
    "\n",
    "                            # this is a check to make sure all words in the line have glove embeddings\n",
    "                            # also good bcus it'll get rid of weird words\n",
    "                            for w in line1:\n",
    "                                #get_word(w)\n",
    "                                self.addWord(w)\n",
    "\n",
    "                            #print(self.word2pho[line1[-1]])\n",
    "                            for v in self.word2pho[line1[-1]]:\n",
    "                                self.addPhoneme(v)\n",
    "\n",
    "                            line1.append('<EOS>')\n",
    "                            line2.append('<EOS>')\n",
    "                            line1.insert(0, '<SOS>')\n",
    "                            line2.insert(0, '<SOS>')\n",
    "\n",
    "                            if line1_vowels[-1] == line2_vowels[-1] and \\\n",
    "                                len(line1) <= self.max_len and len(line1) <= self.max_len and \\\n",
    "                                line1 != line2:\n",
    "\n",
    "                                while len(line1) < self.max_len:\n",
    "                                    line1.append('<PAD>')\n",
    "                                while len(line2) < self.max_len:\n",
    "                                    line2.append('<PAD>')\n",
    "\n",
    "                                self.pairs.append((line1, line2))\n",
    "                        except:\n",
    "                            break\n",
    "\n",
    "        \n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.words2index:\n",
    "            self.words2index[word] = self.n_words\n",
    "            self.words2count[word] = 1\n",
    "            self.index2words[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.words2count[word] += 1\n",
    "            \n",
    "        \n",
    "    def addPhoneme(self, phoneme):\n",
    "        if phoneme not in self.phonemes2index:\n",
    "            self.phonemes2index[phoneme] = self.n_phonemes\n",
    "            self.phonemes2count[phoneme] = 1\n",
    "            self.index2phonemes[self.n_phonemes] = phoneme\n",
    "            self.n_phonemes += 1\n",
    "        else:\n",
    "            self.phonemes2count[phoneme] += 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pairs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lyrics...\n",
      "Lyrics_Tyler,TheCreator.json\n",
      "Lyrics_KanyeWest.json\n",
      "Lyrics_TravisScott.json\n",
      "Lyrics_NickiMinaj.json\n",
      "Lyrics_Wu-TangClan.json\n",
      "Lyrics_MacMiller.json\n",
      "Lyrics_GhostfaceKillah.json\n",
      "Lyrics_Common.json\n",
      "Lyrics_Eminem.json\n",
      "Lyrics_SnoopDogg.json\n",
      "Lyrics_Nas.json\n",
      "Lyrics_OutKast.json\n",
      "Lyrics_N.W.A.json\n",
      "Lyrics_2Pac.json\n",
      "Lyrics_ChildishGambino.json\n",
      "Lyrics_LilWayne.json\n",
      "Lyrics_ChanceTheRapper.json\n",
      "Lyrics_Migos.json\n",
      "Lyrics_Drake.json\n",
      "Lyrics_KidCudi.json\n",
      "Lyrics_Lil_Kim.json\n",
      "Lyrics_Pusha-T.json\n",
      "Lyrics_Future.json\n",
      "Lyrics_A$APRocky.json\n",
      "Lyrics_TheRoots.json\n",
      "Lyrics_TheNotoriousB.I.G..json\n",
      "Lyrics_ATribeCalledQuest.json\n",
      "Lyrics_VinceStaples.json\n",
      "Lyrics_WizKhalifa.json\n",
      "Lyrics_PlayboiCarti.json\n",
      "Lyrics_DMX.json\n",
      "Lyrics_MissyElliott.json\n",
      "Lyrics_ScHoolboyQ.json\n",
      "Lyrics_JAY-Z.json\n",
      "Lyrics_BustaRhymes.json\n",
      "Lyrics_CardiB.json\n",
      "Lyrics_50Cent.json\n",
      "Lyrics_KendrickLamar.json\n",
      "Lyrics_DannyBrown.json\n",
      "Lyrics_J.Cole.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "223223"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = 35\n",
    "lyrData = LyricsDataFrame('/lyric_files', MAX_LEN)\n",
    "len(lyrData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<SOS>',\n",
       "  'little',\n",
       "  'things',\n",
       "  'hoes',\n",
       "  'just',\n",
       "  'be',\n",
       "  'around',\n",
       "  'always',\n",
       "  'bickering',\n",
       "  '<EOS>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>'],\n",
       " ['<SOS>',\n",
       "  'i',\n",
       "  'got',\n",
       "  'some',\n",
       "  'money',\n",
       "  'threw',\n",
       "  'some',\n",
       "  'diamonds',\n",
       "  'on',\n",
       "  'a',\n",
       "  'pinky',\n",
       "  'ring',\n",
       "  '<EOS>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(lyrData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromLine(lyr, line):\n",
    "    l = []\n",
    "    for word in line:\n",
    "        l.append(lyr.words2index[word])\n",
    "    return l\n",
    "\n",
    "\n",
    "def variableFromLine(lyr, line):\n",
    "    indexes = indexesFromLine(lyr, line)\n",
    "    \n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromLine(lyr, pair[0])\n",
    "    target_variable = variableFromLine(lyr, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "\n",
    "def phonemeFromWord(lyr, word):\n",
    "    l = []\n",
    "    #print('word in pFw:', word)\n",
    "    for pho in lyr.word2phoneme[word]:\n",
    "        l.append(pho)\n",
    "\n",
    "    indexes = [lyr.phonemes2index[pho] for pho in l]\n",
    "    \n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class phonemeOnlyEncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, phoneme_vocab_size, phoneme_embedding_size, hidden_size):\n",
    "        super(phonemeOnlyEncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.phonemeEmbedding = nn.Embedding(phoneme_vocab_size, phoneme_embedding_size).cuda()\n",
    "        self.phonemeLSTM = nn.LSTM(phoneme_embedding_size, hidden_size, num_layers=3).cuda()\n",
    "\n",
    "        \n",
    "    def forward(self, ipt, phoHidden):\n",
    "        phonemeEmbedding = self.phonemeEmbedding(ipt).view(1, 1, -1)\n",
    "        phonemeOutput, phonemeHidden = self.phonemeLSTM(phonemeEmbedding, phonemeHidden)\n",
    "        return output, hidden \n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(2, 1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class phonemeOnlyDecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, phoneme_vocab_size, phoneme_embedding_size, hidden_size, \n",
    "                     dropout_p=0.1, max_length=MAX_LEN):\n",
    "        super(phonemeOnlyDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = vocab_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.phoneme_embedding_size = phoneme_embedding_size\n",
    "        self.phoneme_vocab_size = phoneme_vocab_size\n",
    "    \n",
    "        self.phoneme_embedding = nn.Embedding(self.phoneme_vocab_size, self.phoneme_embedding_size).cuda()\n",
    "        self.attn_phoneme = nn.Linear(self.hidden_size + self.phoneme_embedding_size, self.max_length*3).cuda()\n",
    "        self.attn_phoneme_combine = nn.Linear(self.hidden_size*2, self.hidden_size).cuda()\n",
    "        \n",
    "        self.phonemeLSTM = nn.LSTM(self.hidden_size, self.hidden_size).cuda()\n",
    "        self.phoneme_dropout = nn.Dropout(self.dropout_p).cuda()\n",
    "        self.wordoutput = nn.Linear(self.hidden_size, vocab_size).cuda()\n",
    "\n",
    "    \n",
    "    def forward(self, ipt, pho_hidden, encoder_phoneme_outputs):\n",
    "        # ipt will be a word\n",
    "        # phoHidden is the first hidden state\n",
    "        # take the word, convert to phonemes\n",
    "        # take phonemes, starting with phoHidden, feed them into LSTM\n",
    "        # make word prediction based on final output\n",
    "        \n",
    "        phoneme_hidden = pho_hidden\n",
    "        \n",
    "        for phoneme in phonemeFromWord(lyr, input):\n",
    "            phoneme_embedding = self.phoneme_embedding(phoneme).view(1,1,-1)\n",
    "            phoneme_embedding = self.dropout(phoneme_embedding)\n",
    "            \n",
    "            attn_phoneme_weights = F.softmax(\n",
    "                self.attn_phoneme(torch.cat((phoneme_embedding[0], phoneme_hidden[0]), 1)), dim=1)\n",
    "            \n",
    "            attn_phoneme_applied = torch.bmm(attn_phoneme_weights.unsqueeze(0),\n",
    "                                             encoder_phoneme_outputs.unsqueeze(0))\n",
    "            \n",
    "            phoneme_output = torch.cat((phoneme_embedding[0], attn_phoneme_applied[0]), 1)\n",
    "            phoneme_output = self.attn_phoneme_combine(phoneme_output).unsqueeze(0) \n",
    "            phoneme_output = F.relu(phoneme_output)\n",
    "            phoneme_output, phoneme_hidden = self.phonemeLSTM(phoneme_ouput, phoneme_hidden)\n",
    "            \n",
    "        \n",
    "        output = F.relu(phoneme_output)\n",
    "        output = self.word_ouput(output)\n",
    "        output = F.log_softmax(output[0])\n",
    "        return output, phoneme_hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(3, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.1\n",
    "def trainBackwards(input_variable, target_variable, encoder, decoder, \n",
    "                   encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \n",
    "    # input_variable: a sequence of words (to be converted to phonemes) that are fed into the encoder\n",
    "    # target_variable: a sequence of words (which is ALREADY REVERSED and not turned into phonemes) that are fed into the decoder\n",
    "    # encoder, decoder: the encoder + decoder\n",
    "    \n",
    "    lyric_data = lyrData #this is bad srry\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    print(input_variable)\n",
    "    print(target_variable)\n",
    "    input_phonemes = [lyric_data.word2pho[w] for w in input_variable]\n",
    "    #don't need to look at padding for the target variable, so just remove it\n",
    "    target_variable = [x for x in target_variable if x != '<PAD>']\n",
    "    \n",
    "    #print(input_phonemes, target_variable)\n",
    "    \n",
    "    input_length = len(input_phonemes)\n",
    "    target_length = len(target_variable)\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "        \n",
    "    loss = 0\n",
    "    \n",
    "    #phoneme_outputs = []\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_phonemes[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "        #phoneme_outputs.append(encoder_ouput)\n",
    "        \n",
    "    #decoder_input = Variable(torch.LongTensor([[EOS_token]]))\n",
    "    decoder_input = target_variable[0]\n",
    "    decoder_hidden = encoder_hidden\n",
    "    print(decoder_input)\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(1, target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs_words, phoneme_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(1, target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs_words, phoneme_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == SOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(loader, encoder, decoder, n_epochs, print_every=500, plot_every=100, learning_rate=0.003):\n",
    "    # takes in a loader, encoder, decoder, and # of epochs (runs thru the dataset)\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    for epoch in range(n_epochs):\n",
    "        for i_batch, batch in loader:\n",
    "            for pair in batch:\n",
    "                print(pair)\n",
    "                print(type(batch))\n",
    "                input_variable = pair[0]\n",
    "                target_variable = pair[1][::-1]\n",
    "                \n",
    "                loss = trainBackwards(input_variable, target_variable, encoder,\n",
    "                             decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "                print_loss_total += loss\n",
    "                plot_loss_total += loss\n",
    "\n",
    "            if i_batch % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            if i_batch % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                total_plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>', '<SOS>')\n",
      "<class 'list'>\n",
      "<SOS>\n",
      ">SOS<\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'<'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-a0d0018cddc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_1000_tfr_50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_1000_tfr_50_do_20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-27ff58f93a88>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(loader, encoder, decoder, n_epochs, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 loss = trainBackwards(input_variable, target_variable, encoder,\n\u001b[0;32m---> 20\u001b[0;31m                              decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-addf673fbb21>\u001b[0m in \u001b[0;36mtrainBackwards\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0minput_phonemes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlyric_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2pho\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_variable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m#don't need to look at padding for the target variable, so just remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtarget_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_variable\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'<PAD>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-addf673fbb21>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0minput_phonemes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlyric_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2pho\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_variable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m#don't need to look at padding for the target variable, so just remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtarget_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_variable\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'<PAD>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '<'"
     ]
    }
   ],
   "source": [
    "hidden_size = 1000\n",
    "phoneme_embedding_size = 100\n",
    "teacher_forcing_ratio = .5\n",
    "\n",
    "encoder_1000_tfr_50 = phonemeOnlyEncoderRNN(lyrData.n_words, lyrData.n_phonemes,\n",
    "                                        phoneme_embedding_size, hidden_size)\n",
    "decoder_1000_tfr_50_do_20 = phonemeOnlyDecoderRNN(lyrData.n_words, lyrData.n_phonemes, \n",
    "                                                  phoneme_embedding_size, hidden_size, dropout_p=0.2)\n",
    "dataloader = DataLoader(lyrData, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "trainIters(dataloader, encoder_1000_tfr_50, decoder_1000_tfr_50_do_20, 25, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_512_tfr_50.load_state_dict(torch.load('encoder_512_tfr_50.pt'))\n",
    "# decoder_512_tfr_50_do_20.load_state_dict(torch.load('decoder_512_tfr_50_do_20.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. get glove working\n",
    "# 2. make sure network works right\n",
    "# 3. order training short to long <--- might be kinda hard\n",
    "# 4. evaluateAndShowAttention doesn't use beam_search\n",
    "# 5. use both attentions?\n",
    "# Stack phoneme lstm?\n",
    "# stack other lstm? dont get how to increase layers of lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LEN):\n",
    "    input_variable = variableFromLine(lyr, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    \n",
    "    decoder_input = Variable(torch.LongTensor([[EOS_token]]))  # EOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        #print(decoder_attention)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0].cpu()\n",
    "        ni = ni.numpy()\n",
    "        if ni == SOS_token:\n",
    "            decoded_words.append('<SOS>')\n",
    "            break\n",
    "        else:\n",
    "            #print(decoder_output.data.topk(1))\n",
    "            #print(int(ni))\n",
    "            decoded_words.append(lyr.index2phonemes[int(ni)])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[int(ni)]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.rcParams['figure.figsize'] = [10, 5]\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence, encoder, decoder):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence)\n",
    "    print(output_words)\n",
    "    print(\"WARNING: Attentions graph does NOT use beam_search, meaning predictions will be severely worsened\")\n",
    "\n",
    "    showAttention(input_sentence, output_words[::-1], attentions)\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        pair_as_text = normal_pairs[pairs.index(pair)]\n",
    "        print('>', pair[0])\n",
    "        print('>', pair_as_text[0])\n",
    "        print('=', pair[1])\n",
    "        print('=', pair_as_text[1])\n",
    "        phos = evaluateBeamSearch(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(phos)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.1\n",
    "def trainAttentionBackwards(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LEN):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        #print(input_variable[ei])\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "        \n",
    "    #print(input_length)\n",
    "    #print(encoder_outputs.size())\n",
    "    #print(encoder_outputs)\n",
    "        \n",
    "    # first input is EOS because we start predicting from the end of the sentence\n",
    "    decoder_input = Variable(torch.LongTensor([[EOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(1, target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(1, target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == SOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedEncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, phoneme_vocab_size, word_embedding_size, phoneme_embedding_size, hidden_size):\n",
    "        super(CombinedEncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # add if w/ cuda\n",
    "        # self.gloveEmbedding = nn.Embedding(vocab_size, word_embedding_size).cuda()\n",
    "        \n",
    "        self.phonemeEmbedding = nn.Embedding(phoneme_vocab_size, phoneme_embedding_size).cuda()\n",
    "        self.phonemeLSTM = nn.LSTM(phoneme_embedding_size, hidden_size, num_layers=1).cuda()\n",
    "        self.phonemeLinear = nn.Linear(hidden_size, word_embedding_size).cuda() #changes size to match up with glove embedding\n",
    "        \n",
    "        self.scaleVector = nn.Parameter(torch.rand(word_embedding_size)).cuda()\n",
    "        self.b = nn.Parameter(torch.rand(1)).cuda()\n",
    "        self.scaleActivation = nn.Sigmoid()\n",
    "        \n",
    "        self.wordLSTM = nn.LSTM(word_embedding_size, hidden_size, num_layers=1).cuda()\n",
    "        \n",
    "        \n",
    "    def forward(self, ipt, phoHidden):\n",
    "\n",
    "        phonemeHidden = phoHidden\n",
    "        for phoneme in phonemeFromWord(lyr, ipt):\n",
    "            phonemeEmbedding = self.phonemeEmbedding(phoneme).view(1, 1, -1)\n",
    "            phonemeOutput, phonemeHidden = self.phonemeLSTM(phonemeEmbedding, phonemeHidden)\n",
    "            phonemeHiddenList.append(phonemeHidden)\n",
    "            \n",
    "        xchar = self.phonemeLinear(phonemeHidden[0])\n",
    "        \n",
    "        scale = self.scaleActivation(torch.dot(self.scaleVector.view(-1).float(), xchar.view(-1)) + self.b)\n",
    "            \n",
    "        lstmInput = (1-scale)*glove + scale*xchar\n",
    "        output, hidden = self.wordLSTM(lstmInput, wordHidden)\n",
    "        return output, hidden, phonemeHiddenList \n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(2, 1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, phoneme_vocab_size, word_embedding_size, phoneme_embedding_size, hidden_size, \n",
    "                     dropout_p=0.1, max_length=MAX_LEN):\n",
    "        super(CombinedAttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = vocab_size\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.phoneme_embedding_size = phoneme_embedding_size\n",
    "        self.phoneme_vocab_size = phoneme_vocab_size\n",
    "        \n",
    "        \n",
    "        #self.gloveEmbedding = nn.Embedding(vocab_size, word_embedding_size).cuda()\n",
    "        \n",
    "        self.attn_word = nn.Linear(self.hidden_size * 2, self.max_length).cuda()\n",
    "        self.attn_word_combine = nn.Linear(self.hidden_size * 2, self.hidden_size).cuda()\n",
    "        \n",
    "        self.phoneme_embedding = nn.Embedding(self.phoneme_vocab_size, self.phoneme_embedding_size).cuda()\n",
    "        self.attn_phoneme = nn.Linear(self.hidden_size + self.phoneme_embedding_size, self.max_length*3).cuda()\n",
    "        self.attn_phoneme_combine = nn.Linear(self.hidden_size*2, self.hidden_size).cuda()\n",
    "        \n",
    "        self.phonemeLSTM = nn.LSTM(self.hidden_size, self.hidden_size).cuda()\n",
    "        \n",
    "        self.word_dropout = nn.Dropout(self.dropout_p).cuda()\n",
    "        self.phoneme_dropout = nn.Dropout(self.dropout_p).cuda()\n",
    "        \n",
    "        self.combinedLSTM = nn.LSTM(self.hidden_size, self.hidden_size).cuda()\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size).cuda()\n",
    "\n",
    "\n",
    "        #input should be a word so the get_word works right\n",
    "    def forward(self, input, combinedHidden, phoHidden, encoder_word_outputs, encoder_phoneme_outputs):\n",
    "        \n",
    "        phoneme_hidden = phoHidden\n",
    "        \n",
    "        for phoneme in phonemeFromWord(lyr, input):\n",
    "            phoneme_embedding = self.phoneme_embedding(phoneme).view(1,1,-1)\n",
    "            phoneme_embedding = self.dropout(phoneme_embedding)\n",
    "            \n",
    "            attn_phoneme_weights = F.softmax(\n",
    "                self.attn_phoneme(torch.cat((phoneme_embedding[0], phoneme_hidden[0]), 1)), dim=1)\n",
    "            \n",
    "            attn_phoneme_applied = torch.bmm(attn_phoneme_weights.unsqueeze(0),\n",
    "                                             encoder_phoneme_outputs.unsqueeze(0))\n",
    "            \n",
    "            phoneme_output = torch.cat((phoneme_embedding[0], attn_phoneme_applied[0]), 1)\n",
    "            phoneme_output = self.attn_phoneme_combine(phoneme_output).unsqueeze(0) \n",
    "            phoneme_output = F.relu(phoneme_output)\n",
    "            phoneme_output, phoneme_hidden = self.phonemeLSTM(phoneme_ouput, phoneme_hidden)\n",
    "            \n",
    "            \n",
    "        word_embedding = get_word(input)\n",
    "        word_embedding = self.word_dropout(word_embedding)\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((word_embedding[0], combinedHidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_word_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.combinedLSTM(output, combinedHidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(3, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LEN):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size).cuda()\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length).cuda()\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size).cuda()\n",
    "        self.dropout = nn.Dropout(self.dropout_p).cuda()\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size).cuda()\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size).cuda()\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # add if w/ cuda\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size).cuda()\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size).cuda()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_size = 5\n",
    "def evaluateBeamSearch(encoder, decoder, line, reverse=True, max_length=MAX_LEN):\n",
    "    input_variable = variableFromLine(lyr, line)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], \n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    token = EOS_token if reverse else SOS_token\n",
    "    decoder_input = Variable(torch.LongTensor([[token]]))  # SOS or EOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = [] \n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    \n",
    "    beam = beam_search(beam_size, encoder, decoder, line, decoder_input, decoder_hidden, encoder_outputs, reverse=True)\n",
    "    beam_list = []\n",
    "    for b in beam.pho:\n",
    "        beam_list.append(lyr.index2phonemes[b.tolist()])\n",
    "        \n",
    "    if reverse:\n",
    "        beam_list = beam_list[::-1]\n",
    "    #print(beam.attentions)\n",
    "    return beam_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(beam_size, encoder, decoder, line, first_input, first_hidden, encoder_outputs, old_beams=None, reverse=False):\n",
    "    #print('using beam search...')\n",
    "    input_variable = variableFromLine(lyr, line)\n",
    "    \n",
    "    # Get initial decoder outputs. The input is the not up for debate, so it starts every beam as well.\n",
    "    dec_out, dec_hidden, dec_attention = decoder(\n",
    "        first_input, first_hidden, encoder_outputs)\n",
    "    \n",
    "    \n",
    "    #This will start off all of our beams.\n",
    "    dec_hidden_start = dec_hidden\n",
    "    \n",
    "    # take out the predictions, these are our beams\n",
    "    proposed_v, proposed_i = dec_out.data.topk(beam_size)\n",
    "\n",
    "    #convert the indices to list of lists w/ one item\n",
    "    proposed_i = [x for x in proposed_i[0]]\n",
    "    proposed_v = [x for x in proposed_v[0]]\n",
    "    \n",
    "    \n",
    "    if(old_beams is not None):\n",
    "        beams = old_beams\n",
    "    else:\n",
    "        beams = []    \n",
    "        for i in range(beam_size):\n",
    "            beam = Beam(beam_size)\n",
    "\n",
    "            beam.pho.append(proposed_i[i])\n",
    "            beam.prob.append(proposed_v[i])\n",
    "            beam.update_prob(reverse)\n",
    "\n",
    "            beams.append(beam)\n",
    "            \n",
    "    #this for loop should go until all beams are EOS\n",
    "    beams_finished = False\n",
    "    count = 0\n",
    "    while not beams_finished:\n",
    "        count += 1\n",
    "        extended_beams = []\n",
    "        \n",
    "        for j in range(len(beams)):\n",
    "            extended_beams.append(beams[j].extend_beams(beam_size, encoder, decoder, dec_hidden_start, encoder_outputs, reverse))\n",
    "\n",
    "        # we get the extended beams in lists of 5, so now extended beams is a matrix.\n",
    "        # we flatten it to find the highest value easier.\n",
    "\n",
    "        flat_list = []\n",
    "        for sublist in extended_beams:\n",
    "            for item in sublist:\n",
    "                flat_list.append(item)\n",
    "                \n",
    "        flat_list = sorted(flat_list, key=lambda beam: beam.total_sum, reverse=True)\n",
    "            \n",
    "        beams = flat_list[:beam_size]\n",
    "        \n",
    "        # infinite loop, something went wrong.\n",
    "        if count > 31:\n",
    "            return beams[0]\n",
    "            \n",
    "        for beam in beams:\n",
    "            if reverse:\n",
    "                prediction_end = SOS_token\n",
    "            else: \n",
    "                prediction_end = EOS_token\n",
    "                \n",
    "            if beam.pho[-1] == prediction_end or len(beam.pho) > MAX_LEN:\n",
    "                beams_finished = True\n",
    "                #print('success')\n",
    "                return beam\n",
    "                \n",
    "        #print('On search %d:' % count)\n",
    "        #for b in beams:\n",
    "            #print(b.pho, b.total_sum)\n",
    "            \n",
    "    return beams\n",
    "\n",
    "\n",
    "    #       When expanding this beam, check if it's valid. \n",
    "    #       if valid is false and the final pho isn't EOS, \n",
    "    #            dont expand the beam. \n",
    "    #       if valid is false and the final pho is EOS, don't expand but keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Beam(object):\n",
    "    \n",
    "    def __init__(self, beam_width):\n",
    "        self.prob = []\n",
    "        self.pho = []\n",
    "        self.total_sum = 0\n",
    "        self.valid = True\n",
    "        self.beam_width = beam_width\n",
    "        \n",
    "        #this will create an error later\n",
    "        self.attentions = torch.zeros(MAX_LEN, MAX_LEN)\n",
    "\n",
    "        \n",
    "    def extend_beams(self, beam_width, encoder, decoder, first_hidden, encoder_outputs, reverse):\n",
    "        if reverse:\n",
    "            token = SOS_token\n",
    "        else:\n",
    "            token = EOS_token\n",
    "            \n",
    "        if self.pho[-1] == token or self.valid == False:\n",
    "            #print('reached the end of a beam, either it is invalid or the last phoneme is the signal to stop predictions')\n",
    "            return[self]\n",
    "            \n",
    "        guess_hidden = first_hidden\n",
    "        \n",
    "        #first, run the phonemes of the beam thru the decoder, using teacher forcing the whole way\n",
    "        for phoneme_index in self.pho:\n",
    "            dec_input =  Variable(torch.LongTensor([[phoneme_index]]))\n",
    "            dec_input = dec_input.cuda() if use_cuda else dec_input\n",
    "\n",
    "            guess_out, guess_hidden, guess_attention = decoder(\n",
    "                dec_input, guess_hidden, encoder_outputs)\n",
    "            \n",
    "            ind = self.pho.index(phoneme_index)\n",
    "            self.attentions[ind] = guess_attention.data\n",
    "            \n",
    "\n",
    "        # second, take the top beam_size predictions of the final out and put them in new beams\n",
    "        guess_v, guess_i = guess_out.topk(beam_size)\n",
    "\n",
    "        guess_i = [x for x in guess_i[0]]\n",
    "        guess_v = [x for x in guess_v[0]]\n",
    "\n",
    "        extended_beams = []\n",
    "        \n",
    "        for i in range(beam_width):\n",
    "            \n",
    "            new_beam = Beam(beam_width)\n",
    "            for n in self.pho:\n",
    "                new_beam.pho.append(n)\n",
    "                \n",
    "            for p in self.prob:\n",
    "                new_beam.prob.append(p)\n",
    "\n",
    "            new_beam.pho.append(guess_i[i].data[0])\n",
    "            new_beam.prob.append(guess_v[i].data[0]) \n",
    "            new_beam.update_prob(reverse)\n",
    "            \n",
    "            extended_beams.append(new_beam)\n",
    "\n",
    "        \n",
    "        #return the extended beams\n",
    "        return extended_beams\n",
    "\n",
    "\n",
    "    \n",
    "    def update_prob(self, reverse=False):\n",
    "        s = 0\n",
    "        for p in self.prob:\n",
    "             s += p     \n",
    "        if len(self.pho) > 1:\n",
    "            \n",
    "            # [0, 1]\n",
    "            # prev = 0\n",
    "            # cur = 1\n",
    "            for i in range(1, len(self.pho)):\n",
    "                prev = self.pho[i-1]\n",
    "                cur = self.pho[i]\n",
    "                \n",
    "                if reverse:\n",
    "                    try:\n",
    "                        s += math.log(lyr.getCondProbReverse(cur.tolist(), prev.tolist()))\n",
    "                    except:\n",
    "                        self.valid = False\n",
    "                else:\n",
    "                    # P(2|1)\n",
    "                    s += math.log(lyr.getCondProb(cur, prev))\n",
    "\n",
    "                \n",
    "                \n",
    "        self.total_sum = s/len(self.prob)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "good_pairs = [2030,8350,3271,3013,13575,371]\n",
    "for p in good_pairs:\n",
    "    pair = normal_pairs[p]\n",
    "    print(pair)\n",
    "    print(normal_pairs.index(pair))\n",
    "\n",
    "    l = []\n",
    "    for w in clean_line(convert_to_phonemes(pair[0]), []):\n",
    "        for s in w[0]:\n",
    "            l.append(s)\n",
    "\n",
    "    out = evaluateAndShowAttention(l, encoder_512_tfr_50, decoder_512_tfr_50_do_20)\n",
    "    print(out.reverse())\n",
    "    \n",
    "evaluateRandomly(encoder_512_tfr_50, decoder_512_tfr_50_do_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a sound and a line and returns the number of times that sound appears in that line. \n",
    "def traverseLineForMatches(sound, line):\n",
    "    count = 0\n",
    "    for word in line:\n",
    "        try:\n",
    "            for pronunciation in word:\n",
    "                #print(pronunciation)\n",
    "                if sound in pronunciation:\n",
    "                    #print('found a matching sound!')\n",
    "                    count += 1\n",
    "        except:\n",
    "            print('Something went wrong. Skipping this bit....')\n",
    "    #print(sound)\n",
    "    return count\n",
    "\n",
    "\n",
    "# this takes a word (a string or a unicode) and returns the nltk pronunciations without stress numbers\n",
    "# and without duplicate pronunciations. it does NOT choose the best pronunciation from the remaining\n",
    "# list of unique pronunciations for that word\n",
    "\n",
    "def wordWithoutNum(word):\n",
    "    #word = word.decode('utf-8').lower()\n",
    "    s = arpabet[word] #s is a list of lists\n",
    "    stripped_s = []\n",
    "    stripped_s_final = []\n",
    "    for pronunciation in s: #pronunciation is a list of unicode strings\n",
    "        stripped_p = []\n",
    "        for sound in pronunciation: #for every sound, remove digits from the str\n",
    "            stripped_sound = ''.join([i for i in sound if not i.isdigit()])\n",
    "            stripped_p.append(stripped_sound)\n",
    "        stripped_s.append(stripped_p)\n",
    "        \n",
    "    #sometimes removing the numbers creates duplicates, for example:\n",
    "    # arpabet['the'] = [[u'DH', u'AH0'], [u'DH', u'AH1'], [u'DH', u'IY0']] \n",
    "    # after removing digits, we want [[u'DH', u'AH'], [u'DH', u'IY']]\n",
    "    # The following for loop performs this removal\n",
    "    \n",
    "    for pro in stripped_s: \n",
    "        if pro not in stripped_s_final:\n",
    "            stripped_s_final.append(pro)\n",
    "                \n",
    "    return stripped_s_final\n",
    "\n",
    "\n",
    "\n",
    "# this function will ideally take a line and a previous line, where line is an uncleaned list of lists of phonemes,\n",
    "# and prev_line is a cleaned line of phonemes,\n",
    "# and returns the first arguement with no words with multiple pronunciations\n",
    "\n",
    "def clean_line(line, prev_line): \n",
    "\n",
    "    cleaned_line = []\n",
    "    line_as_pure_phonemes = [item for word in line for item in word]\n",
    "    line_as_pure_phonemes = [sound for word in line_as_pure_phonemes for sound in word]\n",
    "    # look at every word in the line\n",
    "    # Line looks like this \n",
    "#     [[[u'IH', u'N']],     In\n",
    "#     [[u'DH', u'AH'], [u'DH', u'IY'], [u'TH', u'AH'], [u'TH', u'IY']], the\n",
    "#     [[u'M', u'IH', u'S', u'T']], mist \n",
    "#     [[u'DH', u'OW']], though\n",
    "#     [[u'B', u'AH', u'T']], but\n",
    "#     [[u'DH', u'AH'], [u'DH', u'IY'], [u'TH', u'AH'], [u'TH', u'IY']], the\n",
    "#     [[u'R', u'IH', u'TH', u'S']], ryth's\n",
    "#     [[u'M', u'UW', u'V']], move\n",
    "#     [[u'IH', u'N']]] in\n",
    "    \n",
    "    \n",
    "    \n",
    "    # word looks like this, here's \"the\": [[u'DH', u'AH'], [u'DH', u'IY'], [u'TH', u'AH'], [u'TH', u'IY']] \n",
    "    for word in line:\n",
    "        \n",
    "        pronunciation_vowels = []\n",
    "        pronunciation_vowels_scores = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(word) != 1:\n",
    "            #print(word)\n",
    "            # pronunciation looks like this: [u'DH', u'AH'], so word[0] = u'DU'\n",
    "            for pronunciation in word:\n",
    "                #Get the vowels for the pronunciations\n",
    "                pronunciation_vowels.append(get_vowels(pronunciation))\n",
    "                \n",
    "            \n",
    "            # v is a list of vowels, could be one but maybe more. is a list\n",
    "            for v in pronunciation_vowels:\n",
    "                count = 0\n",
    "                # for each sound in this v, tally the number of times it appears in the unfiltered list\n",
    "                for sound in v:\n",
    "                    count += line_as_pure_phonemes.count(sound)\n",
    "                    count += prev_line.count(sound)\n",
    "                    \n",
    "                count = count / float(len(v)) #take the average, in case there are 3 vowels in on pro, and 2 in the other\n",
    "                pronunciation_vowels_scores.append(count)\n",
    "               \n",
    "            #find which vowel had the highest count\n",
    "            max_score = max(pronunciation_vowels_scores)\n",
    "\n",
    "            #get the location of the highest count vowel\n",
    "            max_score_index = pronunciation_vowels_scores.index(max_score)\n",
    "            \n",
    "            max_score_vowel = pronunciation_vowels[max_score_index]\n",
    "            cleaned_line.append([word[max_score_index]])\n",
    "            #print(pronunciation_vowels)\n",
    "            #print(pronunciation_vowels_scores)\n",
    "            \n",
    "        # otherwise, only one pronunciation, so append it to the list\n",
    "        else:\n",
    "            cleaned_line.append(word)\n",
    "\n",
    "    return cleaned_line\n",
    "\n",
    "#this is a sample starting line\n",
    "#prev_line = remove_lists(convert_to_phonemes(\"ten after one i think i'll hop the horse\"))\n",
    "#clean_line(convert_to_phonemes(\"hangin' in the good day feelin' good\"), prev_line)\n",
    "# print(convert_to_phonemes(\"a whitened sandwich and again it stopped\"))\n",
    "# print(convert_to_phonemes(\"a derelick makes a real long speech\"))\n",
    "# print(convert_to_phonemes(\"in the mist though but the rhyth's move in\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_phonemes(s):\n",
    "    #filename = 'testfile'\n",
    "    #global arpabet\n",
    "    #filename = os.path.join(\"home\", \"m3\",\"nltk_data\", \"corpora\", \"cmudict\", \"cmudict\")\n",
    "    #print(os.path.abspath(filename))\n",
    "    #filename = \"/home/m3/nltk_data/corpora/cmudict/cmudict\"\n",
    "    s = s.split(' ')\n",
    "    line_phonemes = []\n",
    "    word_phonemes = []\n",
    "    pure = True\n",
    "    \n",
    "    for word in s:\n",
    "        try:\n",
    "            line_phonemes.append(wordWithoutNum(word))\n",
    "        except:\n",
    "            if word[-3:] == \"in'\":\n",
    "                word_in = word\n",
    "                word = word[:-3] + 'ing'\n",
    "                ing_as_phonemes = convert_to_phonemes(word) \n",
    "                print(ing_as_phonemes)\n",
    "                for pro in ing_as_phonemes[0]:\n",
    "                    #print(pro)\n",
    "                    pro[-1] = u'N'\n",
    "                line_phonemes.append(ing_as_phonemes)\n",
    "                #with open(filename,\"a\") as f:\n",
    "                    #print(\"ing_as_phonemes:\", ing_as_phonemes)\n",
    "                    #print(\"ing_as_phonemes[0]:\", ing_as_phonemes[0])\n",
    "                    #print(\"ing_as_phonemes[0][0]:\", ing_as_phonemes[0][0])\n",
    "                    #print(word_in.upper() + \" 1 \" + \" \".join(map(str, ing_as_phonemes[0][0])))\n",
    "                    #f.write(word_in.upper() + \" 1 \" + \" \".join(map(str, ing_as_phonemes[0][0])))\n",
    "                    #f.write(\"\\n\")\n",
    "                #arpabet = nltk.corpus.cmudict.dict()\n",
    "            elif \"'\" in word:\n",
    "                try:\n",
    "                    line_phonemes.append(wordWithoutNum(word.replace(\"'\",\"\")))\n",
    "                except:\n",
    "                    pass\n",
    "                    #print('Deleting an apostrophe didn\\'t work')\n",
    "            elif word == '':\n",
    "                pass\n",
    "            else:\n",
    "                pure = False\n",
    "    return line_phonemes\n",
    "# print(convert_to_phonemes(\"hangin' in the good day feelin' good\"))\n",
    "# print(convert_to_phonemes(\"a whitened sandwich and again it stopped\"))\n",
    "# print(convert_to_phonemes(\"a derelick makes a real long speech\"))\n",
    "#l = convert_to_phonemes(\"after hours 'it' was cool\")\n",
    "#l2 = convert_to_phonemes(\"ten after one i think i'll hop the horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_plot_losses = []\n",
    "def trainItersAttentionBackwards(encoder, decoder, n_iters, plot_losses, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "        \n",
    "        #print(target_variable)\n",
    "        \n",
    "        \n",
    "        # create inverted indices\n",
    "        idx = [i for i in range(target_variable.size(0)-1, -1, -1)]\n",
    "        idx = Variable(torch.cuda.LongTensor(idx))\n",
    "        #print(idx)\n",
    "        inverted_tensor = target_variable.index_select(0, idx)\n",
    "        #print(inverted_tensor)\n",
    "        reversed_list = []\n",
    "        for r in range(len(target_variable.data)):\n",
    "            reversed_list.append(target_variable.data[(len(target_variable.data)-1)-r][0])\n",
    "        \n",
    "        target_variable = inverted_tensor\n",
    "\n",
    "        loss = trainAttentionBackwards(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            #torch.save(encoder.state_dict(), 'encoder_128_tfr_80.pt')\n",
    "            #torch.save(decoder.state_dict(), 'decoder_128_tfr_80_do_50.pt')\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            total_plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH=30\n",
    "def prepareData(name, reverse=False):\n",
    "    # read in all files. Check if each line pair of every song of every artist rhymes\n",
    "    # if it rhymes, put it \n",
    "    \n",
    "    lyr, pairs = readLyrics(name, reverse)\n",
    "    print(\"Reading %s sentence pairs\" % len(pairs))\n",
    "    ## CONVERT TO PHONEMES HERE\n",
    "    pairs_as_phonemes = []\n",
    "    pairs_not_as_phonemes = []\n",
    "    print(\"Counting words...\")\n",
    "    num_of_pairs = 0\n",
    "    for pair in pairs:\n",
    "        cur_phonemes = []\n",
    "        cur_phonemes.append(convert_to_phonemes(pair[0]))\n",
    "        cur_phonemes.append(convert_to_phonemes(pair[1]))\n",
    "        cur_phonemes[0] = clean_line(cur_phonemes[0], cur_phonemes[1])\n",
    "        cur_phonemes[1] = clean_line(cur_phonemes[1], cur_phonemes[0])\n",
    "        \n",
    "        cur_phonemes[0] = [sound for sublist in cur_phonemes[0] for sound in sublist]\n",
    "        cur_phonemes[1] = [sound for sublist in cur_phonemes[1] for sound in sublist]\n",
    "        \n",
    "        foo = []\n",
    "        for w in cur_phonemes[0]:\n",
    "            for s in w:\n",
    "                if s in list_of_phonemes:\n",
    "                    foo.append(s)\n",
    "                \n",
    "        cur_phonemes[0] = foo\n",
    "        \n",
    "        foo = []\n",
    "        for w in cur_phonemes[1]:\n",
    "            for s in w:\n",
    "                if s in list_of_phonemes:\n",
    "                    foo.append(s)\n",
    "                \n",
    "        cur_phonemes[1] = foo\n",
    "        if len(cur_phonemes[0]) < MAX_LENGTH and len(cur_phonemes[1]) < MAX_LENGTH:\n",
    "            num_of_pairs += 1\n",
    "            pairs_as_phonemes.append(cur_phonemes)\n",
    "            pairs_not_as_phonemes.append(pair)\n",
    "            lyr.addLine(cur_phonemes[0])\n",
    "            lyr.addLine(cur_phonemes[1])\n",
    "        \n",
    "    print(\"Pairs under \", MAX_LENGTH)\n",
    "    print(num_of_pairs)\n",
    "    \n",
    "    return lyr, pairs_as_phonemes, pairs_not_as_phonemes\n",
    "\n",
    "\n",
    "lyr, pairs, normal_pairs = prepareData('rap')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLyrics(name):\n",
    "    \n",
    "    lyr = Lyrics(name)\n",
    "    \n",
    "    print('Making Phoneme Dictionary....')\n",
    "    \n",
    "    # These files \n",
    "    words = [word.rstrip('\\n') for word in open('words_in_lyrics')]\n",
    "    pronunciations = [word.rstrip('\\n') for word in open('pho_dict')]\n",
    "    \n",
    "    for ind in range(len(words)):\n",
    "        pro = pronunciations[ind].split()\n",
    "        lyr.addWord2Phoneme(words[ind], pro)\n",
    "        lyr.addWord(words[ind])\n",
    "        \n",
    "    \n",
    "    pairs = []\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    print(\"Reading lyrics...\")\n",
    "    error_counter = 0\n",
    "    pair_counter = 0\n",
    "    for file in os.listdir('lyric_files'):\n",
    "        print(file)\n",
    "        with open('lyric_files/' +file) as f:\n",
    "            data = json.load(f)\n",
    "            for song in data['songs']:\n",
    "                lines = [w.translate(table).lower() for w in song['lyrics'].split('\\n')]\n",
    "                lines_filtered = [i for i in lines if len(i)>0]\n",
    "                lines = lines_filtered #is this needed?\n",
    "                for ind in range(len(lines)-1):\n",
    "                    line1 = lines[ind].split()\n",
    "                    line2 = lines[ind+1].split()\n",
    "                    \n",
    "                    #this gets rid of weird non-ascii characters like right quote and stuff like that \n",
    "                    line1_filtered = [w.encode('ascii',errors='ignore').decode() for w in line1 if len(w.encode('ascii',errors='ignore').decode())>0]\n",
    "                    line2_filtered = [w.encode('ascii',errors='ignore').decode() for w in line2 if len(w.encode('ascii',errors='ignore').decode())>0]\n",
    "\n",
    "                    try:\n",
    "                        line1_vowels = get_vowels(lyr.word2phoneme[line1_filtered[-1]])\n",
    "                        line2_vowels = get_vowels(lyr.word2phoneme[line2_filtered[-1]])\n",
    "\n",
    "                        # this is a check to make sure all words in the line have glove embeddings\n",
    "                        # I think this is also good bcus it'll get rid of really weird words.... might lose some stuff\n",
    "                        for w in line1_filtered:\n",
    "                            get_word(w)\n",
    "\n",
    "                        for v in lyr.word2phoneme[line1_filtered[-1]]:\n",
    "                            lyr.addPhoneme(v)\n",
    "\n",
    "                        if line1_vowels[-1] == line2_vowels[-1]:\n",
    "                            pairs.append((line1_filtered, line2_filtered))\n",
    "                            pair_counter += 1\n",
    "                    except:\n",
    "                        #print(\"Some error occurred here:\")\n",
    "                        #print(line1_filtered, line1_filtered)\n",
    "                        error_counter +=1\n",
    "                        \n",
    "    print(error_counter, pair_counter)\n",
    "\n",
    "            \n",
    "    return lyr, pairs\n",
    "lyr, pairs = readLyrics('rap')\n",
    "MAX_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "\n",
    "class Lyrics:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.phonemes2index = {}\n",
    "        self.phonemes2count = {}\n",
    "        self.index2phonemes = {}\n",
    "        self.phonemes2prob = {}\n",
    "        self.phonemes2probReverse = {}\n",
    "        \n",
    "        self.words2index = {}\n",
    "        self.words2count = {}\n",
    "        self.index2words = {0: \"<SOS>\", 1: \"<EOS>\", 2: \"<PAD>\"}\n",
    "        self.words2prob = {}\n",
    "        self.words2probReverse = {}\n",
    "        \n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "        self.n_phonemes = 0\n",
    "        \n",
    "        self.word2phoneme = {}\n",
    "        \n",
    "        \n",
    "    def addWord2Phoneme(self, word, phonemes):\n",
    "        self.word2phoneme[word] = phonemes\n",
    "\n",
    "    # Takes a line of phonemes and adds it\n",
    "    def addLine(self, line):\n",
    "        for word in line:\n",
    "            self.addWord(word)\n",
    "            \n",
    "        \n",
    "        for i in range(len(line)):\n",
    "            if i+1 < len(line):\n",
    "                self.addProb(line[i], line[i+1])\n",
    "            if i-1 >= 0:\n",
    "                self.addProbReverse(line[i-1], line[i])\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        if word not in self.words2index:\n",
    "            self.words2index[word] = self.n_words\n",
    "            self.words2count[word] = 1\n",
    "            self.index2words[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.words2count[word] += 1\n",
    "            \n",
    "        \n",
    "    def addPhoneme(self, phoneme):\n",
    "        if phoneme not in self.phonemes2index:\n",
    "            self.phonemes2index[phoneme] = self.n_phonemes\n",
    "            self.phonemes2count[phoneme] = 1\n",
    "            self.index2phonemes[self.n_phonemes] = phoneme\n",
    "            self.n_phonemes += 1\n",
    "        else:\n",
    "            self.phonemes2count[phoneme] += 1\n",
    "            \n",
    "            \n",
    "    # Add a counter for P(second|first)\n",
    "    def addProb(self, first, second):\n",
    "        if first not in self.phonemes2prob:\n",
    "            self.phonemes2prob[first] = np.zeros(41)\n",
    "            self.phonemes2prob[first][self.phonemes2index[second]] += 1\n",
    "        else:\n",
    "            self.phonemes2prob[first][self.phonemes2index[second]] += 1\n",
    "        \n",
    "        \n",
    "    # first should be the first phoneme in the sentence when it's read as it would be spoken\n",
    "    # [u'K', u'AE', u'N', u'AY', u'K', u'IH', u'K', u'IH', u'T'] -->  K is first, AE is 2nd\n",
    "    # Add a counter for P(first|second)\n",
    "    def addProbReverse(self, first, second):\n",
    "        if second not in self.phonemes2probReverse:\n",
    "            self.phonemes2probReverse[second] = np.zeros(41)\n",
    "            self.phonemes2probReverse[second][self.phonemes2index[first]] += 1\n",
    "        else:\n",
    "            self.phonemes2probReverse[second][self.phonemes2index[first]] += 1\n",
    "            \n",
    "            \n",
    "    # P(2|1)\n",
    "    def getCondProb(self, first, second):\n",
    "        f = self.index2phonemes[first]\n",
    "        s = self.index2phonemes[second]\n",
    "        return self.phonemes2prob[f][s]/self.phonemes2count[f]\n",
    "    \n",
    "    # P(1|2)\n",
    "    def getCondProbReverse(self, first, second):\n",
    "        f = self.index2phonemes[first]\n",
    "        s = self.index2phonemes[second]\n",
    "        #a = self.phonemes2probReverse[s][first]\n",
    "        #print(a)\n",
    "        return self.phonemes2probReverse[s][first]/self.phonemes2count[s]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
