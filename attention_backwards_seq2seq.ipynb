{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import nltk \n",
    "import copy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "list_of_phonemes = ['AA','AE','AH','AO','AW','AY','B','CH','D','DH','EH','ER','EY','F','G', 'HH', 'IH', 'IY','JH','K','L','M','N','NG','OW','OY','P','R','S','SH','T','TH','UH','UW','V','W','Y','Z','ZH']\n",
    "vowels=[u'AA',u'AE',u'AH',u'AO',u'AW',u'AY',u'EH',u'ER',u'EY',u'IH',u'IY',u'OW',u'OY',u'UH',u'UW',u'Y']\n",
    "arpabet = nltk.corpus.cmudict.dict()\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lyrics:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.phonemes2index = {}\n",
    "        self.phonemes2count = {}\n",
    "        self.index2phonemes = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_phonemes = 2  # Count SOS and EOS\n",
    "\n",
    "    # Takes a line of phonemes and adds it\n",
    "    def addLine(self, line):\n",
    "        for phoneme in line:\n",
    "            self.addPhoneme(phoneme)\n",
    "\n",
    "    def addPhoneme(self, phoneme):\n",
    "        if phoneme not in self.phonemes2index:\n",
    "            self.phonemes2index[phoneme] = self.n_phonemes\n",
    "            self.phonemes2count[phoneme] = 1\n",
    "            self.index2phonemes[self.n_phonemes] = phoneme\n",
    "            self.n_phonemes += 1\n",
    "        else:\n",
    "            self.phonemes2count[phoneme] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLyrics(name, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    indexes_of_pairs = pd.read_csv('rhyming_pairs2.csv', header=1)\n",
    "    \n",
    "    pruned_data = pd.read_csv('pruned_data', header=None)\n",
    "    pruned_data = pruned_data[0]\n",
    "    \n",
    "    pairs = []\n",
    "    for index, row in indexes_of_pairs.iterrows():\n",
    "        first_line = pruned_data[row[0]]\n",
    "        second_line = pruned_data[row[1]]\n",
    "    \n",
    "        pairs.append( (first_line,second_line) )\n",
    "    \n",
    "    # Reverse pairs\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        \n",
    "    lyr = Lyrics(name)\n",
    "\n",
    "    return lyr, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_phonemes(s):\n",
    "    #filename = 'testfile'\n",
    "    #global arpabet\n",
    "    #filename = os.path.join(\"home\", \"m3\",\"nltk_data\", \"corpora\", \"cmudict\", \"cmudict\")\n",
    "    #print(os.path.abspath(filename))\n",
    "    #filename = \"/home/m3/nltk_data/corpora/cmudict/cmudict\"\n",
    "    s = s.split(' ')\n",
    "    line_phonemes = []\n",
    "    word_phonemes = []\n",
    "    pure = True\n",
    "    \n",
    "    for word in s:\n",
    "        try:\n",
    "            line_phonemes.append(wordWithoutNum(word))\n",
    "        except:\n",
    "            if word[-3:] == \"in'\":\n",
    "                word_in = word\n",
    "                word = word[:-3] + 'ing'\n",
    "                ing_as_phonemes = convert_to_phonemes(word) \n",
    "                print(ing_as_phonemes)\n",
    "                for pro in ing_as_phonemes[0]:\n",
    "                    #print(pro)\n",
    "                    pro[-1] = u'N'\n",
    "                line_phonemes.append(ing_as_phonemes)\n",
    "                #with open(filename,\"a\") as f:\n",
    "                    #print(\"ing_as_phonemes:\", ing_as_phonemes)\n",
    "                    #print(\"ing_as_phonemes[0]:\", ing_as_phonemes[0])\n",
    "                    #print(\"ing_as_phonemes[0][0]:\", ing_as_phonemes[0][0])\n",
    "                    #print(word_in.upper() + \" 1 \" + \" \".join(map(str, ing_as_phonemes[0][0])))\n",
    "                    #f.write(word_in.upper() + \" 1 \" + \" \".join(map(str, ing_as_phonemes[0][0])))\n",
    "                    #f.write(\"\\n\")\n",
    "                #arpabet = nltk.corpus.cmudict.dict()\n",
    "            elif \"'\" in word:\n",
    "                try:\n",
    "                    line_phonemes.append(wordWithoutNum(word.replace(\"'\",\"\")))\n",
    "                except:\n",
    "                    pass\n",
    "                    #print('Deleting an apostrophe didn\\'t work')\n",
    "            elif word == '':\n",
    "                pass\n",
    "            else:\n",
    "                pure = False\n",
    "    return line_phonemes\n",
    "# print(convert_to_phonemes(\"hangin' in the good day feelin' good\"))\n",
    "# print(convert_to_phonemes(\"a whitened sandwich and again it stopped\"))\n",
    "# print(convert_to_phonemes(\"a derelick makes a real long speech\"))\n",
    "#l = convert_to_phonemes(\"after hours 'it' was cool\")\n",
    "#l2 = convert_to_phonemes(\"ten after one i think i'll hop the horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function takes a sound and a line and returns the number of times that sound appears in that line. \n",
    "def traverseLineForMatches(sound, line):\n",
    "    count = 0\n",
    "    for word in line:\n",
    "        try:\n",
    "            for pronunciation in word:\n",
    "                #print(pronunciation)\n",
    "                if sound in pronunciation:\n",
    "                    #print('found a matching sound!')\n",
    "                    count += 1\n",
    "        except:\n",
    "            print('Something went wrong. Skipping this bit....')\n",
    "    #print(sound)\n",
    "    return count\n",
    "\n",
    "\n",
    "# this function takes a pronunciation and returns a list of the vowels that appeared in it\n",
    "def find_vowels(pronunciation):\n",
    "    found_vowels = []\n",
    "    for sound in pronunciation:\n",
    "        if sound in vowels:\n",
    "            found_vowels.append(sound)\n",
    "    return found_vowels\n",
    "\n",
    "# this takes a word (a string or a unicode) and returns the nltk pronunciations without stress numbers\n",
    "# and without duplicate pronunciations. it does NOT choose the best pronunciation from the remaining\n",
    "# list of unique pronunciations for that word\n",
    "\n",
    "def wordWithoutNum(word):\n",
    "    #word = word.decode('utf-8').lower()\n",
    "    s = arpabet[word] #s is a list of lists\n",
    "    stripped_s = []\n",
    "    stripped_s_final = []\n",
    "    for pronunciation in s: #pronunciation is a list of unicode strings\n",
    "        stripped_p = []\n",
    "        for sound in pronunciation: #for every sound, remove digits from the str\n",
    "            stripped_sound = ''.join([i for i in sound if not i.isdigit()])\n",
    "            stripped_p.append(stripped_sound)\n",
    "        stripped_s.append(stripped_p)\n",
    "        \n",
    "    #sometimes removing the numbers creates duplicates, for example:\n",
    "    # arpabet['the'] = [[u'DH', u'AH0'], [u'DH', u'AH1'], [u'DH', u'IY0']] \n",
    "    # after removing digits, we want [[u'DH', u'AH'], [u'DH', u'IY']]\n",
    "    # The following for loop performs this removal\n",
    "    \n",
    "    for pro in stripped_s: \n",
    "        if pro not in stripped_s_final:\n",
    "            stripped_s_final.append(pro)\n",
    "                \n",
    "    return stripped_s_final\n",
    "\n",
    "\n",
    "\n",
    "# this function will ideally take a line and a previous line, where line is an uncleaned list of lists of phonemes,\n",
    "# and prev_line is a cleaned line of phonemes,\n",
    "# and returns the first arguement with no words with multiple pronunciations\n",
    "\n",
    "def clean_line(line, prev_line): \n",
    "\n",
    "    cleaned_line = []\n",
    "    line_as_pure_phonemes = [item for word in line for item in word]\n",
    "    line_as_pure_phonemes = [sound for word in line_as_pure_phonemes for sound in word]\n",
    "    # look at every word in the line\n",
    "    # Line looks like this \n",
    "#     [[[u'IH', u'N']],     In\n",
    "#     [[u'DH', u'AH'], [u'DH', u'IY'], [u'TH', u'AH'], [u'TH', u'IY']], the\n",
    "#     [[u'M', u'IH', u'S', u'T']], mist \n",
    "#     [[u'DH', u'OW']], though\n",
    "#     [[u'B', u'AH', u'T']], but\n",
    "#     [[u'DH', u'AH'], [u'DH', u'IY'], [u'TH', u'AH'], [u'TH', u'IY']], the\n",
    "#     [[u'R', u'IH', u'TH', u'S']], ryth's\n",
    "#     [[u'M', u'UW', u'V']], move\n",
    "#     [[u'IH', u'N']]] in\n",
    "    \n",
    "    \n",
    "    \n",
    "    # word looks like this, here's \"the\": [[u'DH', u'AH'], [u'DH', u'IY'], [u'TH', u'AH'], [u'TH', u'IY']] \n",
    "    for word in line:\n",
    "        \n",
    "        pronunciation_vowels = []\n",
    "        pronunciation_vowels_scores = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(word) != 1:\n",
    "            #print(word)\n",
    "            # pronunciation looks like this: [u'DH', u'AH'], so word[0] = u'DU'\n",
    "            for pronunciation in word:\n",
    "                #Get the vowels for the pronunciations\n",
    "                pronunciation_vowels.append(find_vowels(pronunciation))\n",
    "                \n",
    "            \n",
    "            # v is a list of vowels, could be one but maybe more. is a list\n",
    "            for v in pronunciation_vowels:\n",
    "                count = 0\n",
    "                # for each sound in this v, tally the number of times it appears in the unfiltered list\n",
    "                for sound in v:\n",
    "                    count += line_as_pure_phonemes.count(sound)\n",
    "                    count += prev_line.count(sound)\n",
    "                    \n",
    "                count = count / float(len(v)) #take the average, in case there are 3 vowels in on pro, and 2 in the other\n",
    "                pronunciation_vowels_scores.append(count)\n",
    "               \n",
    "            #find which vowel had the highest count\n",
    "            max_score = max(pronunciation_vowels_scores)\n",
    "\n",
    "            #get the location of the highest count vowel\n",
    "            max_score_index = pronunciation_vowels_scores.index(max_score)\n",
    "            \n",
    "            max_score_vowel = pronunciation_vowels[max_score_index]\n",
    "            cleaned_line.append([word[max_score_index]])\n",
    "            #print(pronunciation_vowels)\n",
    "            #print(pronunciation_vowels_scores)\n",
    "            \n",
    "        # otherwise, only one pronunciation, so append it to the list\n",
    "        else:\n",
    "            cleaned_line.append(word)\n",
    "\n",
    "    return cleaned_line\n",
    "\n",
    "#this is a sample starting line\n",
    "#prev_line = remove_lists(convert_to_phonemes(\"ten after one i think i'll hop the horse\"))\n",
    "#clean_line(convert_to_phonemes(\"hangin' in the good day feelin' good\"), prev_line)\n",
    "# print(convert_to_phonemes(\"a whitened sandwich and again it stopped\"))\n",
    "# print(convert_to_phonemes(\"a derelick makes a real long speech\"))\n",
    "# print(convert_to_phonemes(\"in the mist though but the rhyth's move in\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Reading 23694 sentence pairs\n",
      "Counting words...\n",
      "Counted sounds, should be 41\n",
      "41\n",
      "[['AY', 'AO', 'L', 'W', 'EY', 'Z', 'W', 'AO', 'N', 'T', 'IH', 'D', 'T', 'IH', 'F', 'AH', 'K', 'DH', 'AH', 'T', 'B', 'IH', 'CH'], ['TH', 'AE', 'NG', 'K', 'Y', 'UW', 'G', 'AA', 'D', 'AY', 'F', 'AH', 'K', 'T', 'DH', 'AE', 'T', 'B', 'IH', 'CH']]\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH=30\n",
    "def prepareData(name, reverse=False):\n",
    "    lyr, pairs = readLyrics(name, reverse)\n",
    "    print(\"Reading %s sentence pairs\" % len(pairs))\n",
    "    ## CONVERT TO PHONEMES HERE\n",
    "    pairs_as_phonemes = []\n",
    "    pairs_not_as_phonemes = []\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        cur_phonemes = []\n",
    "        cur_phonemes.append(convert_to_phonemes(pair[0]))\n",
    "        cur_phonemes.append(convert_to_phonemes(pair[1]))\n",
    "        cur_phonemes[0] = clean_line(cur_phonemes[0], cur_phonemes[1])\n",
    "        cur_phonemes[1] = clean_line(cur_phonemes[1], cur_phonemes[0])\n",
    "        \n",
    "        cur_phonemes[0] = [sound for sublist in cur_phonemes[0] for sound in sublist]\n",
    "        cur_phonemes[1] = [sound for sublist in cur_phonemes[1] for sound in sublist]\n",
    "        \n",
    "        foo = []\n",
    "        for w in cur_phonemes[0]:\n",
    "            for s in w:\n",
    "                if s in list_of_phonemes:\n",
    "                    foo.append(s)\n",
    "                \n",
    "        cur_phonemes[0] = foo\n",
    "        \n",
    "        foo = []\n",
    "        for w in cur_phonemes[1]:\n",
    "            for s in w:\n",
    "                if s in list_of_phonemes:\n",
    "                    foo.append(s)\n",
    "                \n",
    "        cur_phonemes[1] = foo\n",
    "        if len(cur_phonemes[0]) < MAX_LENGTH and len(cur_phonemes[1]) < MAX_LENGTH:\n",
    "            pairs_as_phonemes.append(cur_phonemes)\n",
    "            pairs_not_as_phonemes.append(pair)\n",
    "            lyr.addLine(cur_phonemes[0])\n",
    "            lyr.addLine(cur_phonemes[1])\n",
    "        \n",
    "    print(\"Counted sounds, should be 41\")\n",
    "    print(lyr.n_phonemes)\n",
    "    \n",
    "    return lyr, pairs_as_phonemes, pairs_not_as_phonemes\n",
    "\n",
    "\n",
    "lyr, pairs, normal_pairs = prepareData('rap')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromLine(lyr, line):\n",
    "    l = []\n",
    "    #print(line)\n",
    "    for phoneme in line:\n",
    "        l.append(lyr.phonemes2index[phoneme])\n",
    "    return l\n",
    "#[lyr.phonemes2index[phoneme] for phoneme in line]\n",
    "\n",
    "\n",
    "def variableFromLine(lyr, line):\n",
    "    indexes = indexesFromLine(lyr, line)\n",
    "    indexes.insert(0, SOS_token)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromLine(lyr, pair[0])\n",
    "    target_variable = variableFromLine(lyr, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH+2):\n",
    "    input_variable = variableFromLine(lyr, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    \n",
    "    decoder_input = Variable(torch.LongTensor([[EOS_token]]))  # EOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == SOS_token:\n",
    "            decoded_words.append('<SOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(lyr.index2phonemes[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        pair_as_text = normal_pairs[pairs.index(pair)]\n",
    "        print('>', pair[0])\n",
    "        print('>', pair_as_text[0])\n",
    "        print('=', pair[1])\n",
    "        print('=', pair_as_text[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.rcParams['figure.figsize'] = [10, 5]\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence, encoder, decoder):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder, decoder, input_sentence)\n",
    "    #print('input =', input_sentence)\n",
    "    #print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words.reverse(), attentions)\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.1\n",
    "def trainAttentionBackwards(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH+2):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "        \n",
    "    decoder_input = Variable(torch.LongTensor([[EOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(1, target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(1, target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == SOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainItersAttentionBackwards(encoder, decoder, n_iters, plot_losses, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        # create inverted indices\n",
    "        idx = [i for i in range(target_variable.size(0)-1, -1, -1)]\n",
    "        idx = Variable(torch.LongTensor(idx))\n",
    "        inverted_tensor = target_variable.index_select(0, idx)\n",
    "        #print(inverted_tensor)\n",
    "        reversed_list = []\n",
    "        for r in range(len(target_variable.data)):\n",
    "            reversed_list.append(target_variable.data[(len(target_variable.data)-1)-r][0])\n",
    "        \n",
    "        target_variable = inverted_tensor\n",
    "\n",
    "        loss = trainAttentionBackwards(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            torch.save(encoder.state_dict(), 'encoder_512_tfr_50_100000.pt')\n",
    "            torch.save(decoder.state_dict(), 'decoder_512_tfr_50_100000.pt')\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH+2):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 39s (- 49m 14s) (1000 1%) 2.8524\n",
      "1m 15s (- 46m 1s) (2000 2%) 2.5689\n",
      "1m 52s (- 44m 54s) (3000 4%) 2.5434\n",
      "2m 27s (- 43m 44s) (4000 5%) 2.4778\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-08343c31bd20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplot_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtrainItersAttentionBackwards\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_512_tfr_100_new_rhyme\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_512_tfr_100_new_rhyme\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m75000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-f67ae81966ba>\u001b[0m in \u001b[0;36mtrainItersAttentionBackwards\u001b[1;34m(encoder, decoder, n_iters, plot_losses, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         loss = trainAttentionBackwards(input_variable, target_variable, encoder,\n\u001b[1;32m---> 29\u001b[1;33m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-8c75f09f6554>\u001b[0m in \u001b[0;36mtrainAttentionBackwards\u001b[1;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             decoder_output, decoder_hidden, decoder_attention = decoder(\n\u001b[1;32m---> 33\u001b[1;33m                 decoder_input, decoder_hidden, encoder_outputs)\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Teacher forcing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-fa9329775758>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         )\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[0mnexth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                 \u001b[0mhy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[1;31m# hack to handle LSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[1;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mb_ih\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mgi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mgh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m    990\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "teacher_forcing_ratio = .5\n",
    "encoder_256_tfr_50 = EncoderRNN(lyr.n_phonemes, hidden_size)\n",
    "decoder_256_tfr_50 = AttnDecoderRNN(hidden_size, lyr.n_phonemes, dropout_p=0.1)\n",
    "\n",
    "#encoder_512_tfr_100_new_rhyme.load_state_dict(torch.load('encoder_512_tfr_100_new_rhyme.pt'))\n",
    "#decoder_512_tfr_100_new_rhyme.load_state_dict(torch.load('decoder_512_tfr_50_100000.pt'))\n",
    "\n",
    "plot_losses = []\n",
    "trainItersAttentionBackwards(encoder_512_tfr_100_new_rhyme, decoder_512_tfr_100_new_rhyme, 75000, plot_losses, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(encoder_256_tfr_50.state_dict(), \"encoder_256_tfr_50.pt\")\n",
    "torch.save(decoder_256_tfr_50.state_dict(), \"decoder_256_tfr_50.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beam_search(beam_size, encoder, decoder, line, first_input, first_hidden, encoder_outputs, old_beams=None, reverse=False):\n",
    "    input_variable = variableFromLine(lyr, line)\n",
    "    \n",
    "    # Get initial decoder outputs. The input is the not up for debate, so it starts every beam as well.\n",
    "    dec_out, dec_hidden, dec_attention = decoder(\n",
    "        first_input, first_hidden, encoder_outputs)\n",
    "    \n",
    "    \n",
    "    #This will start off all of our beams.\n",
    "    dec_hidden_start = dec_hidden\n",
    "    \n",
    "    # take out the predictions, these are our beams\n",
    "    proposed_v, proposed_i = dec_out.data.topk(beam_size)\n",
    "\n",
    "    #convert the indices to list of lists w/ one item\n",
    "    proposed_i = [x for x in proposed_i[0]]\n",
    "    proposed_v = [x for x in proposed_v[0]]\n",
    "    \n",
    "    \n",
    "    if(old_beams is not None):\n",
    "        print('got old beams!')\n",
    "        beams = old_beams\n",
    "    else:\n",
    "        print('using new beams.....')\n",
    "        beams = []    \n",
    "        for i in range(beam_size):\n",
    "            beam = Beam(beam_size)\n",
    "\n",
    "            beam.pho.append(proposed_i[i])\n",
    "            beam.prob.append(proposed_v[i])\n",
    "            beam.update_prob(reverse)\n",
    "\n",
    "            beams.append(beam)\n",
    "            \n",
    "    #this for loop should go until all beams are EOS\n",
    "    beams_finished = False\n",
    "    count = 0\n",
    "    while not beams_finished:\n",
    "        count += 1\n",
    "        extended_beams = []\n",
    "\n",
    "        for j in range(len(beams)):\n",
    "            extended_beams.append(beams[j].extend_beams(beam_size, encoder, decoder, dec_hidden_start, reverse))\n",
    "\n",
    "        # we get the extended beams in lists of 5, so now extended beams is a matrix.\n",
    "        # we flatten it to find the highest value easier.\n",
    "\n",
    "        flat_list = []\n",
    "        for sublist in extended_beams:\n",
    "            for item in sublist:\n",
    "                flat_list.append(item)\n",
    "        flat_list = sorted(flat_list, key=lambda beam: beam.total_sum, reverse=True)\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "        beams = flat_list[:beam_size]\n",
    "        \n",
    "        for beam in beams:\n",
    "            if reverse:\n",
    "                prediction_end = SOS_token\n",
    "            else: \n",
    "                prediction_end = EOS_token\n",
    "                \n",
    "            if beam.pho[-1] == prediction_end:\n",
    "                beams_finished = True\n",
    "            else:\n",
    "                beams_finished = False\n",
    "                \n",
    "        print('On search %d:' % count)\n",
    "        for b in flat_list[:beam_size]:\n",
    "            print(b.pho, b.total_sum)\n",
    "    return beams\n",
    "\n",
    "\n",
    "    #       When expanding this beam, check if it's valid. \n",
    "    #       if valid is false and the final pho isn't EOS, \n",
    "    #            dont expand the beam. \n",
    "    #       if valid is false and the final pho is EOS, don't expand but keep\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Beam(object):\n",
    "    \n",
    "    def __init__(self, beam_width):\n",
    "        self.prob = []\n",
    "        self.pho = []\n",
    "        self.total_sum = 0\n",
    "        self.valid = True\n",
    "        self.beam_width = beam_width\n",
    "\n",
    "        \n",
    "    def extend_beams(self, beam_width, encoder, decoder, first_hidden, reverse):\n",
    "        if reverse:\n",
    "            token = SOS_token\n",
    "        else:\n",
    "            token = EOS_token\n",
    "            \n",
    "        if self.pho[-1] == token or self.valid == False:\n",
    "            print('reached the end of a beam, either it is invalid or the last phoneme is the signal to stop predictions')\n",
    "            return[self]\n",
    "            \n",
    "        guess_hidden = first_hidden\n",
    "        \n",
    "        #first, run the phonemes of the beam thru the decoder, using teacher forcing the whole way\n",
    "        for phoneme_index in self.pho:\n",
    "            dec_input =  Variable(torch.LongTensor([[phoneme_index]]))\n",
    "            #print(dec_input)\n",
    "            print(guess_hidden.shape)\n",
    "            print(encoder_outputs.shape)\n",
    "            guess_out, guess_hidden, guess_attention = decoder(\n",
    "                dec_input, guess_hidden, encoder_outputs)\n",
    "            \n",
    "\n",
    "        # second, take the top beam_size predictions of the final out and put them in new beams\n",
    "        guess_v, guess_i = guess_out.topk(beam_size)\n",
    "\n",
    "        guess_i = [x for x in guess_i[0]]\n",
    "        guess_v = [x for x in guess_v[0]]\n",
    "\n",
    "        extended_beams = []\n",
    "        \n",
    "        for i in range(beam_width):\n",
    "            \n",
    "            new_beam = Beam(beam_width)\n",
    "            for n in self.pho:\n",
    "                new_beam.pho.append(n)\n",
    "                \n",
    "            for p in self.prob:\n",
    "                new_beam.prob.append(p)\n",
    "\n",
    "            new_beam.pho.append(guess_i[i].data[0])\n",
    "            new_beam.prob.append(guess_v[i].data[0]) \n",
    "            new_beam.update_prob(reverse)\n",
    "            \n",
    "            extended_beams.append(new_beam)\n",
    "\n",
    "            \n",
    "        \n",
    "        #print('here are the extended_beams we just made:')\n",
    "        #for i in range(len(extended_beams)):\n",
    "        #    print(extended_beams[i].pho)\n",
    "        \n",
    "        #return the extended beams\n",
    "        return extended_beams\n",
    "\n",
    "\n",
    "    \n",
    "    def update_prob(self, reverse=False):\n",
    "        s = 0\n",
    "        for p in self.prob:\n",
    "             s += p     \n",
    "        if len(self.pho) > 1:\n",
    "            \n",
    "            # [0, 1]\n",
    "            # prev = 0\n",
    "            # cur = 1\n",
    "            for i in range(1, len(self.pho)):\n",
    "                prev = self.pho[i-1]\n",
    "                cur = self.pho[i]\n",
    "                \n",
    "            #try:\n",
    "                if reverse:\n",
    "                    # P(1|2)\n",
    "                    # want prob cur appears given the pred of prev <-- works i think then\n",
    "                    s += math.log(lyr.getCondProbReverse(cur, prev))\n",
    "                else:\n",
    "                    # P(2|1)\n",
    "                    s += math.log(lyr.getCondProb(cur, prev))\n",
    "#             except:\n",
    "#                 print('something went wrong, probabily cond_prob is 0')\n",
    "#                 print(cur, prev)\n",
    "                \n",
    "                \n",
    "        self.total_sum = s/len(self.prob)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateRandomlyAttention(encoder, attn_decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        pair_as_text = normal_pairs[pairs.index(pair)]\n",
    "        print('>', pair[0])\n",
    "        print('>', pair_as_text[0])\n",
    "        print('=', pair[1])\n",
    "        print('=', pair_as_text[1])\n",
    "\n",
    "        output_words, attentions = evaluateAttention(encoder, attn_decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beam_size = 5\n",
    "def evaluateAttentionBackwards(encoder, decoder, line, reverse=False, max_length=MAX_LENGTH+2):\n",
    "    input_variable = variableFromLine(lyr, line)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    #print(encoder_hidden)\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        #print(ei)\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], \n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    token = EOS_token if reverse else SOS_token\n",
    "    decoder_input = Variable(torch.LongTensor([[token]]))  # SOS or EOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = [] \n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    \n",
    "    beams, beam_values = beam_search(beam_size, encoder, decoder, line,\n",
    "                                     decoder_input, decoder_hidden, encoder_outputs, reverse=True)\n",
    "    \n",
    "    print(beams)\n",
    "    print(beam_values)\n",
    "    \n",
    "\n",
    "    return beams, beam_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_pairs = [8350,2030,3271,3013,13575,371]\n",
    "for p in good_pairs:\n",
    "    pair = normal_pairs[p]\n",
    "    print(pair)\n",
    "    print(normal_pairs.index(pair))\n",
    "\n",
    "    l = []\n",
    "    for w in clean_line(convert_to_phonemes(pair[0]), []):\n",
    "        for s in w[0]:\n",
    "            l.append(s)\n",
    "    #print(l)\n",
    "\n",
    "    out = evaluateAndShowAttention(l, encoder_512_tfr_100_new_rhyme, decoder_512_tfr_100_new_rhyme)\n",
    "    print(out.reverse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
